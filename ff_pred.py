# -*- coding: utf-8 -*-
"""FF_pred.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VQRQx3Lyciwm5Iy6Fx-z2fib4tRJCJZM

#Importing libraries and cleaned_df_Eg dataset
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

warnings.filterwarnings("ignore")
df=pd.read_csv('df_final.csv')
pd.set_option('display.max_columns', None)
df.head(2)

print(df.isna().sum().sum())

"""#Data Prep"""

dfx=df.iloc[:,4:-1]
X=dfx.values
y=df.iloc[:,2].values
y=y.reshape(len(y),1)
dfx

"""#Ensemble Learning

##Random Forest
"""

from sklearn.ensemble import RandomForestRegressor
X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.15, random_state=142)
rf=RandomForestRegressor(random_state=42)
rf.fit(X_train1,y_train1)

# Calculate cross-validated RMSE
mse_scores1 = cross_val_score(estimator=rf, X=X_train1, y=y_train1, cv=5, scoring='neg_mean_squared_error')
rmse_scores1 = np.sqrt(-mse_scores1)
print("RMSE: {:.4f}".format(rmse_scores1.mean()))
print("Standard Deviation: {:.4f}".format(rmse_scores1.std()))

#RF on Test set
y_pred1=rf.predict(X_test1)
y_pred1=y_pred1.reshape(len(y_pred1),1)
r_value1 = np.corrcoef(y_test1.squeeze(), y_pred1.squeeze())[0, 1]

# Calculate metrics on the test set
print("R2 on Test Set:", r2_score(y_test1, y_pred1))
print("R value:", r_value1)
print("MAE on Test Set:", mean_absolute_error(y_test1, y_pred1))
print("MSE on Test Set:", mean_squared_error(y_test1, y_pred1))
print("RMSE on Test Set:", np.sqrt(mean_squared_error(y_test1, y_pred1)))

#RF on Train set
y_train_pred1 = rf.predict(X_train1)
y_train_pred1=y_train_pred1.reshape(len(y_train_pred1),1)
r_value_p1 = np.corrcoef(y_train1.squeeze(), y_train_pred1.squeeze())[0, 1]

# Calculate metrics on the test set
print("R2 on Train Set:", r2_score(y_train1, y_train_pred1))
print("R value:", r_value_p1)
print("MAE on Train Set:", mean_absolute_error(y_train1, y_train_pred1))
print("MSE on Train Set:", mean_squared_error(y_train1, y_train_pred1))
print("RMSE on Train Set:", np.sqrt(mean_squared_error(y_train1, y_train_pred1)))

np.set_printoptions(precision=2, suppress=True)
print(np.concatenate((y_pred1.reshape(len(y_pred1),1), y_test1.reshape(len(y_test1),1)),1))

# Plotting the results for the training set
plt.figure(figsize=(4.5, 4))

plt.plot(y_train1, y_train1, color='black', label='Actual Values')
plt.scatter(y_train1, y_train_pred1, color='royalblue', label='Train set: 0.0158 RMSE')
plt.scatter(y_test1, y_pred1, color='deeppink', label='Test set: 0.0311 RMSE')

plt.xlabel('Actual FF')
plt.ylabel('Predicted FF')
plt.legend()
#plt.grid(True)
plt.title('RF Model: Actual vs Predicted FF')
plt.savefig('RF_FF.png', dpi=300, bbox_inches='tight')

plt.tight_layout()
plt.show()

"""##Gradient Boosting"""

from sklearn.ensemble import GradientBoostingRegressor
X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.15,  random_state=142)
gbr=GradientBoostingRegressor(random_state=42)
gbr.fit(X_train2, y_train2)

# Calculate cross-validated RMSE
mse_scores2 = cross_val_score(estimator=gbr, X=X_train2, y=y_train2, cv=5, scoring='neg_mean_squared_error')
rmse_scores2 = np.sqrt(-mse_scores2)
print("RMSE: {:.4f}".format(rmse_scores2.mean()))
print("Standard Deviation: {:.4f}".format(rmse_scores2.std()))

#GBR on test set
y_pred2=gbr.predict(X_test2)
y_pred2=y_pred2.reshape(len(y_pred2),1)
r_value2 = np.corrcoef(y_test2.squeeze(), y_pred2.squeeze())[0, 1]

# Calculate metrics on the test set
print("R2 on Test Set:", r2_score(y_test2, y_pred2))
print("R value:", r_value2)
print("MAE on Test Set:", mean_absolute_error(y_test2, y_pred2))
print("MSE on Test Set:", mean_squared_error(y_test2, y_pred2))
print("RMSE on Test Set:", np.sqrt(mean_squared_error(y_test2, y_pred2)))

#GBR on train set
y_train_pred2 = gbr.predict(X_train2)
y_train_pred2=y_train_pred2.reshape(len(y_train_pred2),1)
r_value_p2 = np.corrcoef(y_train2.squeeze(), y_train_pred2.squeeze())[0, 1]

# Calculate metrics on the test set
print("R2 on Test Set:", r2_score(y_train2, y_train_pred2))
print("R value:", r_value_p2)
print("MAE on Test Set:", mean_absolute_error(y_train2, y_train_pred2))
print("MSE on Test Set:", mean_squared_error(y_train2, y_train_pred2))
print("RMSE on Test Set:", np.sqrt(mean_squared_error(y_train2, y_train_pred2)))

np.set_printoptions(precision=2,suppress=True)
print(np.concatenate((y_pred2.reshape(len(y_pred2),1), y_test2.reshape(len(y_test2),1)),1))

# Plotting the results for the training set
plt.figure(figsize=(4.5, 4))
plt.plot(y_train2, y_train2, color='black', label='Actual Values')
plt.scatter(y_train2, y_train_pred2, edgecolors='royalblue',
                linewidth=1.2,color='royalblue', label='Train set: 0.0258 RMSE')
plt.scatter(y_test2, y_pred2, edgecolors='deeppink',
                linewidth=1.2,color='deeppink', label='Test set: 0.0351 RMSE')
plt.xlabel('Actual FF')
plt.ylabel('Predicted FF')
plt.legend()
#plt.grid(True)
plt.title('GBR Model: Actual vs Predicted FF')
plt.savefig('GBR_FF.png', dpi=300, bbox_inches='tight')


plt.tight_layout()
plt.show()

"""##XGBoost"""

import xgboost as xgb
X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.15, random_state=142)
xgb = xgb.XGBRegressor(random_state=42)
xgb.fit(X_train3,y_train3)

mse_scores3 = cross_val_score(estimator = xgb, X = X_train3, y = y_train3, cv = 5, scoring='neg_mean_squared_error')
rmse_scores3 = np.sqrt(-mse_scores3)
print("RMSE: {:.4f}".format(rmse_scores3.mean()))
print("Standard Deviation: {:.4f}".format(rmse_scores3.std()))

#XGB on Test set
y_pred3=xgb.predict(X_test3)
y_pred3=y_pred3.reshape(len(y_pred3),1)
r_value3 = np.corrcoef(y_test3.squeeze(), y_pred3.squeeze())[0, 1]

# Calculate metrics on the test set
print("R2 on Test Set:", r2_score(y_test3, y_pred3))
print("R value:", r_value3)
print("MAE on Test Set:", mean_absolute_error(y_test3, y_pred3))
print("RMSE on Test Set:", np.sqrt(mean_squared_error(y_test3, y_pred3)))

#XGB on Train set
y_train_pred3 = xgb.predict(X_train3)

y_train_pred3=y_train_pred3.reshape(len(y_train_pred3),1)
r_value_p3 = np.corrcoef(y_train3.squeeze(), y_train_pred3.squeeze())[0, 1]

# Calculate metrics on the test set
print("R2 on Train Set:", r2_score(y_train3, y_train_pred3))
print("R value:", r_value_p3)
print("MAE on Train Set:", mean_absolute_error(y_train3, y_train_pred3))
print("MSE on Train Set:", mean_squared_error(y_train3, y_train_pred3))
print("RMSE on Train Set:", np.sqrt(mean_squared_error(y_train3, y_train_pred3)))

print(np.concatenate((y_pred3.reshape(len(y_pred3),1), y_test3.reshape(len(y_test3),1)),1))

y_train_pred3 = xgb.predict(X_train3)
# Plotting the results for the training set
plt.figure(figsize=(4.5, 4))

plt.plot(y_train3, y_train3, color='black', label='Actual Values')
plt.scatter(y_train3, y_train_pred3, color='royalblue', label='Train set: 0.0034 RMSE')
plt.scatter(y_test3, y_pred3, color='deeppink', label='Test set: 0.0375 RMSE')

plt.xlabel('Actual FF')
plt.ylabel('Predicted FF')
plt.legend()
#plt.grid(True)
plt.title('XGB Model: Actual vs Predicted FF')
plt.savefig('XGB_FF.png', dpi=300, bbox_inches='tight')

plt.tight_layout()
plt.show()

"""##CatBoost"""

!pip install catboost

from catboost import CatBoostRegressor
X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=0.15, random_state=142)
catboost = CatBoostRegressor(random_state=42)
catboost.fit(X_train4, y_train4, verbose=0)

# Evaluating with cross-validation
mse_scores4 = cross_val_score(estimator = catboost, X = X_train4, y = y_train4, cv = 5, scoring='neg_mean_squared_error')
rmse_scores4 = np.sqrt(-mse_scores4)
print("RMSE: {:.4f}".format(rmse_scores4.mean()))
print("Standard Deviation: {:.4f}".format(rmse_scores4.std()))

#CB on Test set
y_pred4 = catboost.predict(X_test4)
y_pred4 = y_pred4.reshape(len(y_pred4), 1)
r_value4 = np.corrcoef(y_test4.squeeze(), y_pred4.squeeze())[0, 1]

# Calculate metrics on the test set
print("R2 on Test Set:", r2_score(y_test4, y_pred4))
print("R value:", r_value4)
print("MAE on Test Set:", mean_absolute_error(y_test4, y_pred4))
print("MSE on Test Set:", mean_squared_error(y_test4, y_pred4))
print("RMSE on Test Set:", np.sqrt(mean_squared_error(y_test4, y_pred4)))

#CB on Train set
y_train_pred4 = catboost.predict(X_train4)

y_train_pred4=y_train_pred4.reshape(len(y_train_pred4),1)
r_value_p4 = np.corrcoef(y_train4.squeeze(), y_train_pred4.squeeze())[0, 1]

# Calculate metrics on the test set
print("R2 on Train Set:", r2_score(y_train4, y_train_pred4))
print("R value:", r_value_p4)
print("MAE on Train Set:", mean_absolute_error(y_train4, y_train_pred4))
print("MSE on Train Set:", mean_squared_error(y_train4, y_train_pred4))
print("RMSE on Train Set:", np.sqrt(mean_squared_error(y_train4, y_train_pred4)))

np.set_printoptions(precision=2, suppress=True)
print(np.concatenate((y_pred4.reshape(len(y_pred4),1), y_test4.reshape(len(y_test4),1)),1))

# Plotting the results for the training set
plt.figure(figsize=(4.5, 4))

plt.plot(y_train4, y_train4, color='black', label='Actual Values')
plt.scatter(y_train4, y_train_pred4, color='royalblue', label='Train Set: 0.0137 RMSE')
plt.scatter(y_test4, y_pred4, color='deeppink', label='Test set: 0.0351 RMSE')

plt.xlabel('Actual FF')
plt.ylabel('Predicted FF')
plt.legend()
#plt.grid(True)
plt.title('CB Model: Actual vs Predicted FF')
plt.savefig('CB_FF.png', dpi=300, bbox_inches='tight')

plt.tight_layout()
plt.show()

"""#SHAP Analysis"""

pip install shap

import shap
shap.initjs()

dfx.shape

col=dfx.columns
dfx_test = pd.DataFrame(data=X, columns=col)

explainer=shap.Explainer(rf)
shap_values=explainer(dfx_test[0:])

np.shape(shap_values.values)

#plt.figure(figsize=(10, 3))
shap.summary_plot(shap_values, plot_type='violin')
plt.show()

shap.summary_plot(shap_values, plot_type='violin', show=False)

plt.savefig("shap_summary.png", dpi=300, bbox_inches="tight")
plt.close()

plt.figure(figsize=(10, 4))
shap.summary_plot(
    shap_values,
    plot_type="violin",   # beeswarm style
    max_display=7
)

plt.savefig("shap_summary.png", dpi=300, bbox_inches="tight")
plt.show()

shap.summary_plot(shap_values, plot_type='violin',max_display=7, show=False)

plt.savefig("shap_summary.png", dpi=300, bbox_inches="tight")
plt.close()

plt.figure(figsize=(5, 3))
shap.plots.bar(shap_values)
plt.show()

# Scatter plot without background distribution
shap.plots.scatter(shap_values[:, 'BG'],color=shap_values[:,'Sn'], show=False, hist=False)


# Set axis limits
#plt.xlim(1.1, 2.6)
# plt.ylim(-1, 1)

plt.show()

shap.plots.scatter(shap_values[:, 'BG'],color=shap_values[:,'Sn'], show=False, hist=False)

plt.savefig("FD_BG.png", dpi=300, bbox_inches="tight")
plt.close()

shap.plots.scatter(shap_values[:,'Pb'], show=False)

# set axis limits according to your requirement
#plt.xlim(1.1, 2.6)
#plt.ylim(-1, 1)

plt.show()

shap.plots.scatter(shap_values[:,'FA'],color=shap_values[:,'BG'], hist=False)

shap.plots.scatter(shap_values[:,'FA'],color=shap_values[:,'BG'],show=False, hist=False)
plt.savefig("FD_FA.png", dpi=300, bbox_inches="tight")
plt.close()

shap.plots.scatter(shap_values[:,'Sn'],show=False, hist=False)

plt.savefig("FD_Sn.png", dpi=300, bbox_inches="tight")
plt.close()

shap.plots.scatter(shap_values[:,'CBO'],color=shap_values[:,'BG'])

shap.plots.scatter(shap_values[:,'VBO'],color=shap_values[:,'BG'])

shap.plots.scatter(shap_values[:,'FA'])

shap.plots.scatter(shap_values[:,'FA'], show=False, hist=False)
plt.savefig("FD_FA.png", dpi=300, bbox_inches="tight")
plt.close()